{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from mlbt.utils import PurgedKFold\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "def clf_hyper_fit(\n",
    "    feat,\n",
    "    lbl,\n",
    "    t1,\n",
    "    pipe_clf,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    bagging=[0, None, 1.0],\n",
    "    rnd_search_iter=0,\n",
    "    n_jobs=-1,\n",
    "    pct_embargo=0,\n",
    "    **fit_params,\n",
    "):\n",
    "    if set(lbl.values) == {0, 1}:\n",
    "        scoring = \"f1\"  # f1 for meta-labeling\n",
    "    else:\n",
    "        scoring = \"neg_log_loss\"  # symmetric towards all classes\n",
    "\n",
    "    # 1) hyperparameter searching, on train data\n",
    "    inner_cv = PurgedKFold(\n",
    "        n_splits=cv, t1=t1, pct_embargo=pct_embargo, random_state=None\n",
    "    )\n",
    "    if rnd_search_iter == 0:\n",
    "        gs = GridSearchCV(\n",
    "            estimator=pipe_clf,\n",
    "            param_grid=param_grid,\n",
    "            scoring=scoring,\n",
    "            cv=inner_cv,\n",
    "            n_jobs=n_jobs,\n",
    "            iid=False,\n",
    "        )\n",
    "    else:\n",
    "        gs = RandomizedSearchCV(\n",
    "            estimator=pipe_clf,\n",
    "            param_distributions=param_grid,\n",
    "            scoring=scoring,\n",
    "            cv=inner_cv,\n",
    "            n_jobs=n_jobs,\n",
    "            iid=False,\n",
    "            n_iter=rnd_search_iter,\n",
    "        )\n",
    "    gs = gs.fit(feat, lbl, **fit_params)\n",
    "    return gs\n",
    "\n",
    "\n",
    "RF_PARAM_GRID = {\n",
    "    \"n_estimators\": np.arange(25, 525, 25),\n",
    "    \"max_depth\": np.arange(1, 11, 1),\n",
    "}\n",
    "\n",
    "XGB_PARAM_GRID = {\n",
    "    \"max_depth\": np.arange(1, 8, 1),\n",
    "    \"colsample_bytree\": np.arange(0.3, 1.1, 0.1),\n",
    "    \"gamma\": np.arange(0.0, 0.55, 0.05),\n",
    "    \"n_estimators\": np.arange(25, 275, 25),\n",
    "}\n",
    "\n",
    "LGBM_PARAM_GRID = {\n",
    "    \"max_depth\": np.arange(1, 8, 1),\n",
    "    \"num_leaves\": np.arange(8, 130, 2),\n",
    "    \"colsample_bytree\": np.arange(0.3, 1.05, 0.05),\n",
    "    \"n_estimators\": np.arange(25, 275, 25),\n",
    "}\n",
    "\n",
    "KNN_PARAM_GRID = {\"n_neighbors\": np.arange(1, 31, 1), \"p\": np.arange(1, 4, 1)}\n",
    "\n",
    "SVC_PARAM_GRID = {\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"probability\": [True],\n",
    "}\n",
    "\n",
    "PARALLELIZABLE = [\"xgboost\", \"lgbm\", \"knn\"]\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    events,\n",
    "    X_all,\n",
    "    y_all,\n",
    "    clf_type,\n",
    "    optimize_hypers,\n",
    "    hypers_n_iter,\n",
    "    num_threads=32,\n",
    "    n_jobs=4,\n",
    "    hyper_params=None,\n",
    "):\n",
    "    # X_all and y_all in this context are X_train and y_train in the grander scheme\n",
    "    logging.info(f\"Getting model {clf_type}\")\n",
    "    param_grids = {\n",
    "        \"random_forest\": RF_PARAM_GRID,\n",
    "        \"xgboost\": XGB_PARAM_GRID,\n",
    "        \"lgbm\": LGBM_PARAM_GRID,\n",
    "        \"svc\": SVC_PARAM_GRID,\n",
    "        \"knn\": KNN_PARAM_GRID,\n",
    "        \"dummy\": {},\n",
    "    }\n",
    "    clfs = {\n",
    "        \"random_forest\": RandomForestClassifier,\n",
    "        \"xgboost\": XGBClassifier,\n",
    "        \"lgbm\": LGBMClassifier,\n",
    "        \"svc\": SVC,\n",
    "        \"knn\": KNeighborsClassifier,\n",
    "        \"dummy\": DummyClassifier,\n",
    "    }\n",
    "\n",
    "    hyper_params = hyper_params or {}\n",
    "    extra_hyper_params = {}\n",
    "\n",
    "    # Balance class weights\n",
    "    if clf_type == \"random_forest\":\n",
    "        extra_hyper_params[\"class_weight\"] = \"balanced_subsample\"\n",
    "    if clf_type in [\"xgboost\", \"lgbm\"]:\n",
    "        neg, pos = y_all.value_counts().values\n",
    "        extra_hyper_params[\"scale_pos_weight\"] = neg / pos\n",
    "\n",
    "    clf = clfs[clf_type](**hyper_params, **extra_hyper_params)\n",
    "\n",
    "    param_grid = param_grids[clf_type]\n",
    "    if not param_grid:  # nothing to do\n",
    "        return clf, hyper_params\n",
    "\n",
    "    if not hyper_params and optimize_hypers:\n",
    "        # We generally expect to be run with high num_threads which means we don't have to parallelize at the clf level here\n",
    "        clf.n_jobs = 1\n",
    "        logging.info(\n",
    "            f\"hyperparam search n_iter={hypers_n_iter} for {clf_type} on num_threads={num_threads} and n_jobs={clf.n_jobs}\"\n",
    "        )\n",
    "        \n",
    "        search = clf_hyper_fit(\n",
    "            feat=X_all,\n",
    "            lbl=y_all,\n",
    "            t1=events[\"t1\"],\n",
    "            pipe_clf=clf,\n",
    "            param_grid=param_grid,\n",
    "            rnd_search_iter=hypers_n_iter,\n",
    "            n_jobs=num_threads,\n",
    "        )\n",
    "        search_results = pd.DataFrame(search.cv_results_)\n",
    "        best1_idx = search_results[\"mean_test_score\"].idxmax()\n",
    "\n",
    "        clf, hyper_params = (\n",
    "            search.best_estimator_,\n",
    "            search_results.iloc[best1_idx][\"params\"],\n",
    "        )\n",
    "\n",
    "    clf.n_jobs = n_jobs\n",
    "    return clf, hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
