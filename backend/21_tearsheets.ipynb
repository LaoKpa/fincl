{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tearsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doda\\Anaconda3\\envs\\fincl2\\lib\\site-packages\\pyfolio\\pos.py:28: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  ' to position notionals.'\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "import pyfolio\n",
    "from pyfolio.timeseries import perf_stats, gen_drawdown_table\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import simplejson as json\n",
    "\n",
    "from mlbt.historical_bt import simulate_pnl\n",
    "from mlbt.pnl_sim import get_pnl_reports\n",
    "\n",
    "try:\n",
    "    from mlbt import settings_pers as settings\n",
    "except:\n",
    "    from mlbt import settings\n",
    "\n",
    "FORMAT = \"%(asctime)-15s %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "def mean_of_dfs(dfs):\n",
    "    return reduce(lambda left, right: left.add(right), dfs) / len(dfs)\n",
    "\n",
    "def make_default_config(**data):\n",
    "    DATA_DIR = data.get(\"DATA_DIR\", settings.DATA_DIR)\n",
    "\n",
    "    return {\n",
    "        \"DATA_DIR\": DATA_DIR,\n",
    "        \"F_PAYLOAD_DIR\": data.get(\"F_PAYLOAD_DIR\", settings.F_PAYLOAD_DIR),\n",
    "        \"symbols_map\": pd.read_csv(DATA_DIR / \"symbols.csv\", index_col=\"iqsymbol\")\n",
    "    }\n",
    "\n",
    "\n",
    "def create_frontend_payload_multi(file_names, force=False, our_config=None):\n",
    "    if our_config is None:\n",
    "        our_config = make_default_config()\n",
    "\n",
    "    new_file_name = our_config[\"F_PAYLOAD_DIR\"] / \"f_payload_MULTI.json\"\n",
    "\n",
    "    \n",
    "def abort_early(force, file_name):\n",
    "    have_file = False\n",
    "    if not force:\n",
    "        try:\n",
    "            # Check if we already have the file we want to create\n",
    "            with open(file_name) as f:\n",
    "                have_file = bool(json.load(f))\n",
    "        except:\n",
    "            pass\n",
    "        if have_file:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "\n",
    "def load_payloads(file_names, our_config):\n",
    "    res = []\n",
    "    for file_name in file_names:\n",
    "        with open(file_name) as f:\n",
    "            pay_j = json.load(f)\n",
    "\n",
    "        events = pd.DataFrame.from_dict(pay_j[\"events\"])\n",
    "        events = events.set_index(pd.to_datetime(events.index))\n",
    "        events[\"t1\"] = pd.to_datetime(events[\"t1\"])\n",
    "        config = get_config(pay_j, file_name)\n",
    "        config = {**config, **our_config}\n",
    "\n",
    "        closes, clf_signals, alpha_signals = get_pnl_reports(\n",
    "            events,\n",
    "            pay_j[\"symbols\"],\n",
    "            config[\"binarize\"],\n",
    "            config[\"binarize_params\"],\n",
    "        )\n",
    "        logging.info(f\"clf_signals shape {clf_signals.shape}\")\n",
    "\n",
    "        primary_signals, secondary_signals = (\n",
    "            (alpha_signals, clf_signals)\n",
    "            if alpha_signals is not None\n",
    "            else (clf_signals, alpha_signals)\n",
    "        )\n",
    "        res.append((config, pay_j, closes, primary_signals, secondary_signals))\n",
    "\n",
    "    return res\n",
    "\n",
    "def join_signals(dfs):\n",
    "    cols = dfs[0].columns\n",
    "    signals = []\n",
    "    for col in cols:\n",
    "        symbol_signals = pd.concat([df[col] for df in dfs], axis=1).ffill().mean(axis=1)\n",
    "        signals.append(symbol_signals)\n",
    "    res = pd.concat(signals, axis=1).ffill()\n",
    "    res.columns = cols\n",
    "    return res\n",
    "\n",
    "\n",
    "def create_frontend_payload(file_names, force=False, our_config=None):\n",
    "    combine_multi = len(file_names) > 1\n",
    "    if our_config is None:\n",
    "        our_config = make_default_config()\n",
    "    \n",
    "    if combine_multi:\n",
    "        new_file_name = our_config[\"F_PAYLOAD_DIR\"] / f\"f_payload_MULTI_{len(file_names)}.json\"\n",
    "    else:\n",
    "        new_file_name = our_config[\"F_PAYLOAD_DIR\"] / file_name.basename().replace(\"payload_\", \"f_payload_\", 1)\n",
    "    \n",
    "    if abort_early(force, new_file_name):\n",
    "        return\n",
    "    \n",
    "    payloads = load_payloads(file_names, our_config)\n",
    "    configs, pay_js, closes, primary_signals, secondary_signals = zip(*payloads)\n",
    "    config = configs[0]\n",
    "    pay_j = pay_js[0]\n",
    "    closes = closes[0]\n",
    "\n",
    "    primary_signals = join_signals(primary_signals)\n",
    "    if secondary_signals[0]:\n",
    "        secondary_signals = join_signals(secondary_signals)\n",
    "    \n",
    "    primary_rets, pay_j[\"primary\"][\"pnl\"] = create_tearsheet(\n",
    "        config, closes, primary_signals, new_file_name, \"primary\"\n",
    "    )\n",
    "    if pay_j[\"secondary\"]:\n",
    "        _, pay_j[\"secondary\"][\"pnl\"] = create_tearsheet(\n",
    "            config, closes, secondary_signals, new_file_name, \"secondary\", primary_rets\n",
    "        )\n",
    "\n",
    "    # Delete stuff we don't want in the frontend payload\n",
    "    del pay_j[\"events\"]\n",
    "    del pay_j[\"symbols\"]\n",
    "\n",
    "    logging.info(f\"Writing f_payload at {new_file_name}\")\n",
    "    with open(new_file_name, \"w\") as f:\n",
    "        json.dump(pay_j, f, ignore_nan=True, default=datetime.datetime.isoformat)\n",
    "    return new_file_name\n",
    "\n",
    "    \n",
    "\n",
    "def calc_returns(df):\n",
    "    df = df.resample(\"1B\").last()\n",
    "\n",
    "    if str(df.index.tz) != \"UTC\":\n",
    "        df.index = df.index.tz_localize(tz=\"UTC\")\n",
    "\n",
    "    return df.pct_change()\n",
    "\n",
    "\n",
    "def create_tearsheet(config, close, signal, file_name, report_type, benchmark_rets=None):\n",
    "    logging.info(f\"Creating {report_type} tearsheet for {file_name}\")\n",
    "    # Map long/short to long/flat\n",
    "    signal = (signal + 1) / 2\n",
    "    pos_size = 20000\n",
    "    df_net, df_gross, cost_stats = simulate_pnl(config, close, signal, pos_size)\n",
    "    returns_net = calc_returns(df_net)\n",
    "    returns_net.name = report_type.title()\n",
    "    returns_gross = calc_returns(df_gross)\n",
    "    returns_gross.name = report_type.title()\n",
    "\n",
    "    if report_type == \"primary\":\n",
    "        long_all = pd.DataFrame(1, columns=signal.columns, index=signal.index)\n",
    "        df_bench, _, _ = simulate_pnl(config, close, long_all, pos_size)\n",
    "        benchmark_rets = calc_returns(df_bench)\n",
    "        benchmark_rets.name = \"Benchmark (long all)\"\n",
    "\n",
    "    \n",
    "    fig = pyfolio.create_returns_tear_sheet(\n",
    "        returns_net, benchmark_rets=benchmark_rets, return_fig=True\n",
    "    )\n",
    "    fig_file_name = file_name.replace(\".json\", f\"_{report_type}.png\")\n",
    "    fig.savefig(fig_file_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "    p_stats = perf_stats(returns_net)\n",
    "    p_stats_wo_costs = perf_stats(returns_gross)\n",
    "    dd_table = gen_drawdown_table(returns_net, 5)\n",
    "\n",
    "    signal = signal.resample(\"1B\").last()\n",
    "    # Just-in-case normalize to 1 for reporting\n",
    "    signal = signal / signal.max().max()\n",
    "    signal.plot()\n",
    "    signal = signal.set_index(signal.index.map(lambda x: x.isoformat()))\n",
    "    \n",
    "\n",
    "    return (\n",
    "        returns_net,\n",
    "        {\n",
    "            \"fig_file_name\": str(Path(fig_file_name).basename()),\n",
    "            \"p_stats\": p_stats.to_dict(),\n",
    "            \"p_stats_wo_costs\": p_stats_wo_costs.to_dict(),\n",
    "            \"dd_table\": dd_table.to_dict(),\n",
    "            \"signal\": signal.to_csv(),  # CSVs are a lot more space-efficient for this dense 1500*50 table\n",
    "            \"cost_stats\": cost_stats,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def get_config(payload, fn):\n",
    "    if \"config\" in payload:\n",
    "        return payload[\"config\"]\n",
    "\n",
    "    # bridge to the old payload format\n",
    "    if \"fixed_horizon\" in fn:\n",
    "        return {\n",
    "            \"binarize\": \"fixed_horizon\",\n",
    "            \"binarize_params\": int(re.findall(r\"fixed_horizon_(\\d+)\", fn)[0]),\n",
    "        }\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
