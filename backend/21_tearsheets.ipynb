{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tearsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pyfolio\n",
    "from pyfolio.timeseries import perf_stats, gen_drawdown_table\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import simplejson as json\n",
    "\n",
    "from mlbt.historical_bt import simulate_pnl\n",
    "from mlbt.pnl_sim import get_pnl_reports\n",
    "\n",
    "try:\n",
    "    from mlbt import settings_pers as settings\n",
    "except:\n",
    "    from mlbt import settings\n",
    "\n",
    "FORMAT = \"%(asctime)-15s %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "\n",
    "def make_default_config(**data):\n",
    "    DATA_DIR = data.get(\"DATA_DIR\", settings.DATA_DIR)\n",
    "\n",
    "    return {\n",
    "        \"DATA_DIR\": DATA_DIR,\n",
    "        \"F_PAYLOAD_DIR\": data.get(\"F_PAYLOAD_DIR\", settings.F_PAYLOAD_DIR),\n",
    "        \"symbols_map\": pd.read_csv(DATA_DIR / \"symbols.csv\", index_col=\"iqsymbol\")\n",
    "    }\n",
    "    \n",
    "def create_frontend_payload(file_name, force=False, our_config=None):\n",
    "    if our_config is None:\n",
    "        our_config = make_default_config()\n",
    "\n",
    "    new_file_name = our_config[\"F_PAYLOAD_DIR\"] / file_name.basename().replace(\"payload_\", \"f_payload_\", 1)\n",
    "    have_file = False\n",
    "    if not force:\n",
    "        try:\n",
    "            # Check if we already have the file we want to create\n",
    "            with open(new_file_name) as f:\n",
    "                have_file = bool(json.load(f))\n",
    "        except:\n",
    "            pass\n",
    "        if have_file:\n",
    "            return\n",
    "    with open(file_name) as f:\n",
    "        pay_j = json.load(f)\n",
    "\n",
    "    events = pd.DataFrame.from_dict(pay_j[\"events\"])\n",
    "    events = events.set_index(pd.to_datetime(events.index))\n",
    "    events[\"t1\"] = pd.to_datetime(events[\"t1\"])\n",
    "    config = get_config(pay_j, file_name)\n",
    "    config = {**config, **our_config}\n",
    "\n",
    "    closes, clf_signals, alpha_signals = get_pnl_reports(\n",
    "        events,\n",
    "        pay_j[\"symbols\"],\n",
    "        config[\"binarize\"],\n",
    "        config[\"binarize_params\"],\n",
    "    )\n",
    "    primary_signals, secondary_signals = (\n",
    "        (alpha_signals, clf_signals)\n",
    "        if alpha_signals is not None\n",
    "        else (clf_signals, alpha_signals)\n",
    "    )\n",
    "    primary_rets, pay_j[\"primary\"][\"pnl\"] = create_tearsheet(\n",
    "        config, closes, primary_signals, new_file_name, \"primary\"\n",
    "    )\n",
    "    if pay_j[\"secondary\"]:\n",
    "        _, pay_j[\"secondary\"][\"pnl\"] = create_tearsheet(\n",
    "            config, closes, secondary_signals, new_file_name, \"secondary\", primary_rets\n",
    "        )\n",
    "\n",
    "    # Delete stuff we don't want in the frontend payload\n",
    "    del pay_j[\"events\"]\n",
    "    del pay_j[\"symbols\"]\n",
    "\n",
    "    logging.info(f\"Writing f_payload at {new_file_name}\")\n",
    "    with open(new_file_name, \"w\") as f:\n",
    "        json.dump(pay_j, f, ignore_nan=True, default=datetime.datetime.isoformat)\n",
    "    return new_file_name\n",
    "\n",
    "\n",
    "def calc_returns(df):\n",
    "    df = df.resample(\"1B\").last()\n",
    "\n",
    "    if str(df.index.tz) != \"UTC\":\n",
    "        df.index = df.index.tz_localize(tz=\"UTC\")\n",
    "\n",
    "    return df.pct_change()\n",
    "\n",
    "\n",
    "def create_tearsheet(config, close, signal, file_name, report_type, benchmark_rets=None):\n",
    "    logging.info(f\"Creating {report_type} tearsheet for {file_name}\")\n",
    "    # Map long/short to long/flat\n",
    "    signal = (signal + 1) / 2\n",
    "    pos_size = 10000\n",
    "    df, df_wo_costs, cost_stats = simulate_pnl(config, close, signal, pos_size)\n",
    "    returns = calc_returns(df)\n",
    "    returns.name = report_type.title()\n",
    "    returns_wo_costs = calc_returns(df_wo_costs)\n",
    "    returns_wo_costs.name = report_type.title()\n",
    "\n",
    "    if report_type == \"primary\":\n",
    "        long_all = pd.DataFrame(1, columns=signal.columns, index=signal.index)\n",
    "        df_bench, _, _ = simulate_pnl(config, close, long_all, pos_size)\n",
    "        benchmark_rets = calc_returns(df_bench)\n",
    "        benchmark_rets.name = \"Benchmark (long all)\"\n",
    "\n",
    "    \n",
    "    fig = pyfolio.create_returns_tear_sheet(\n",
    "        returns, benchmark_rets=benchmark_rets, return_fig=True\n",
    "    )\n",
    "    fig_file_name = file_name.replace(\".json\", f\"_{report_type}.png\")\n",
    "    fig.savefig(fig_file_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "    p_stats = perf_stats(returns)\n",
    "    p_stats_wo_costs = perf_stats(returns_wo_costs)\n",
    "    dd_table = gen_drawdown_table(returns, 5)\n",
    "\n",
    "    signal = signal.resample(\"1B\").last()\n",
    "    # Just-in-case normalize to 1 for reporting\n",
    "    signal = signal / signal.max().max()\n",
    "    signal.plot()\n",
    "    signal = signal.set_index(signal.index.map(lambda x: x.isoformat()))\n",
    "    \n",
    "\n",
    "    return (\n",
    "        returns,\n",
    "        {\n",
    "            \"fig_file_name\": str(Path(fig_file_name).basename()),\n",
    "            \"p_stats\": p_stats.to_dict(),\n",
    "            \"p_stats_wo_costs\": p_stats_wo_costs.to_dict(),\n",
    "            \"dd_table\": dd_table.to_dict(),\n",
    "            \"signal\": signal.to_csv(),  # CSVs are a lot more space-efficient for this dense 1500*50 table\n",
    "            \"cost_stats\": cost_stats,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def get_config(payload, fn):\n",
    "    if \"config\" in payload:\n",
    "        return payload[\"config\"]\n",
    "\n",
    "    # bridge to the old payload format\n",
    "    if \"fixed_horizon\" in fn:\n",
    "        return {\n",
    "            \"binarize\": \"fixed_horizon\",\n",
    "            \"binarize_params\": int(re.findall(r\"fixed_horizon_(\\d+)\", fn)[0]),\n",
    "        }\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
